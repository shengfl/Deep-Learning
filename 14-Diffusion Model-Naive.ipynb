{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d390f5a4-5620-40cd-80e2-84c76b87539c",
   "metadata": {},
   "source": [
    "## 1. 扩散模型（Diffusion Model）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "10b2bef8-0a55-4987-8b42-7886809552f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://lilianweng.github.io/posts/2021-07-11-diffusion-models/DDPM.png\" width=\"600\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "url = 'https://lilianweng.github.io/posts/2021-07-11-diffusion-models/DDPM.png'\n",
    "display(Image(url=url, width=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada9a134-d114-457d-bb41-0edd136d3ac3",
   "metadata": {},
   "source": [
    "分两个方向：\n",
    "\n",
    "**正向过程（扩散过程）**：将原始数据（如图像）逐步添加高斯噪声，最终转化为纯噪声。每一步的噪声强度由预设的调度策略控制（如线性增加噪声）。这一过程是确定性的，不需要学习。\n",
    "\n",
    "**逆向过程（去噪过程）**：模型通过训练学习如何逐步去除噪声，将纯噪声还原为原始数据。这是扩散模型的核心：通过神经网络（如U-Net）预测每一步的噪声，并迭代去噪。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652b2758-3284-4680-8329-d45570610f62",
   "metadata": {},
   "source": [
    "## 2. 数学表达式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a00b280-5abc-4ca5-856f-f9a688749600",
   "metadata": {},
   "source": [
    "### 2.1 正向过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db09408d-49b6-4d6e-89ac-7c041c61cdf4",
   "metadata": {},
   "source": [
    "将数据 $x_0$ 逐步添加高斯噪声，在T步之后，变为纯噪声 $x_T\\sim\\mathcal{N}(0,I)$  \n",
    "\n",
    "假设从真实分布中取样 $x_0$ 服从某个分布 $x_0 \\sim q(x)$  \n",
    "\n",
    "$t$ 时刻的分布只取决于前一时刻 $t-1$ 的状态（马尔可夫性）  \n",
    "\n",
    "$\\beta_t$ 是 $t$ 时刻加入的噪声比例，预设的噪声调度参数（例如线性增长或余弦调度）    \n",
    "\n",
    "$q(x_t|x_{t-1})=\\mathcal{N}(x_t; \\sqrt{1-\\beta_t} x_{t-1}, \\beta_tI))$  \n",
    "\n",
    "通过重参数化技巧，可以从 $x_0$ 直接计算任意 $t$ 时刻的 $x_t=\\sqrt{\\bar\\alpha_t}x_0+\\sqrt{1-\\bar\\alpha_t}\\epsilon,  \\epsilon\\sim\\mathcal{N}(0,I)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca024595-a5eb-448c-b43a-b52c33d319df",
   "metadata": {},
   "source": [
    "推导过程：  \n",
    "\n",
    "$$x_t = \\sqrt{1-\\beta_t} x_{t-1} + \\sqrt\\beta_t\\epsilon_{t-1} $$\n",
    "$$=\\sqrt{1-\\beta_t}(\\sqrt{1-\\beta_{t-1}} x_{t-2} + \\sqrt{\\beta_{t-1}}\\epsilon_{t-2})+ \\sqrt\\beta_t\\epsilon_{t-1}$$\n",
    "$$=\\sqrt{1-\\beta_t}\\sqrt{1-\\beta_{t-1}} x_{t-2} + \\sqrt{1-\\beta_t}\\sqrt{\\beta_{t-1}}\\epsilon_{t-2}+ \\sqrt\\beta_t\\epsilon_{t-1}=\\cdots$$\n",
    "$$=\\prod_{i=1}^t\\sqrt{1-\\beta_i}x_0 + \\sqrt\\beta_t\\epsilon_{t-1} + \\sqrt{1-\\beta_t}\\sqrt{\\beta_{t-1}}\\epsilon_{t-2} + \\cdots $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd21c55-a8e1-4036-988c-589ce4c51826",
   "metadata": {},
   "source": [
    "除第一项外，剩余项为n个标准正态分布的叠加，方差\n",
    "$$\\sigma^2=\\beta_t+(1-\\beta_t)\\beta_{t-1}+\\cdots$$\n",
    "令$$\\alpha_t=1-\\beta_t$$\n",
    "有\n",
    "$$\\sigma^2=1-\\alpha_t+\\alpha_t(1-\\alpha_{t-1})+\\cdots$$\n",
    "$$=1-\\prod_{i=1}^t\\alpha_i$$ \n",
    "于是\n",
    "$$x_t=\\left(\\prod_{i=1}^t(1-\\beta_i) \\right)^{1/2}x_0+\\left(1-\\prod_{i=1}^t(1-\\beta_i)\\right)^{1/2}\\epsilon, \\ \\epsilon\\sim\\mathcal{N}(0,I)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2f7441-48f8-4454-80ee-d240fa7edd97",
   "metadata": {},
   "source": [
    "定义$$\\bar\\alpha_t:=\\prod_{i=1}^t(1-\\beta_i)$$\n",
    "表示前 $t$ 步累积的噪声保留率。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4203f834-5630-4fe1-a355-e9eb27d783b1",
   "metadata": {},
   "source": [
    "### 2.2 逆向过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d253b5-f163-4d65-a0f6-ea3f0a200397",
   "metadata": {},
   "source": [
    "从噪声 $x_T\\sim\\mathcal{N}(0,I)$  逐步还原出原始数据 $x_0$\n",
    "\n",
    "当$\\beta_t$较小时，假设逆过程也是高斯的，于是 $q(x_{t-1}|x_t)$ 是高斯的。在给定 $x_0$ 的情况下，$q(x_{t-1}|x_t, x_0)$ 是有解析解的。\n",
    "\n",
    "**根据 $x_0$ 已知程度的不同**，可以对应一些不同的应用场景。如果完全已知，则可以用来检验模型效果；若部分已知，如被遮挡，给定部分像素或 mask，条件扩散模型引导生成合理的其余图像部分；采用类似的图像，则可以生成具有相同风格/结构的新图像；如果给定的是图像所属类别标签，如\"狗\"、\"猫\"，模型从高斯噪声生成对应图像；也可以给定一段自然语言的描述，生成图像。\n",
    "\n",
    "一般情况下这个分布很难计算，于是希望找到另外一个变分分布 $p_\\theta$ 去迫近，也就是我们需要学习的模型。\n",
    "$$p_\\theta(x_{t-1} | x_t) = \\mathcal{N}(x_{t-1}; \\mu_\\theta(x_t, t), \\Sigma_\\theta(x_t, t))$$\n",
    "其中 $ \\mu_\\theta $ 和$  \\Sigma_\\theta  $是神经网络学习的均值和方差。这个过程类似于VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d08748-faba-435f-8251-1f78dfff980a",
   "metadata": {},
   "source": [
    "[Ho et al. (2020)](https://arxiv.org/pdf/2006.11239) 提出，只在每个时间步最小化：\n",
    "$$\\mathbb{E}_{x_0,\\epsilon,t}\\left[||\\epsilon-\\epsilon_\\theta (x_t,t)||^2\\right]$$\n",
    "等价于对 ELBO 的近似优化。\n",
    "\n",
    "从闭式采样中得到 $x_t=\\sqrt{\\bar\\alpha_t}x_0+\\sqrt{1-\\bar\\alpha_t}\\epsilon$\n",
    "\n",
    "将 $x_t$ 传入一个神经网络，训练其预测原始噪声, 得到预测结果 $\\hat\\epsilon$\n",
    "\n",
    "直接采用MSE作为损失函数。 $L_t = \\mathbb{E}_{x_0,\\epsilon}\\left[||\\epsilon-\\epsilon_\\theta (\\sqrt{\\bar\\alpha_t}x_0+\\sqrt{1-\\bar\\alpha_t}\\epsilon,t)||^2\\right]$\n",
    "\n",
    "有了预测噪声 $\\hat\\epsilon$，用其构造 $\\hat x_0$ ，利用 $x_0$ 已知情况下 $q(x_{t-1}|x_t, x_0)$ 的闭式解公式来更新参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2d6368-89de-42bc-9af6-3f01edd16835",
   "metadata": {},
   "source": [
    "当 $x_0$ 已知时， $q(x_{t-1}|x_t, x_0)=\\mathcal{N}(x_{t-1};\\tilde{mu}(x_t,x_0),\\tilde{\\beta_t}I)$ 的闭式解为：\n",
    "$$\\tilde{\\beta_t}=\\frac{1-\\bar\\alpha_{t-1}}{1-\\bar\\alpha_t}\\cdot \\beta_t$$\n",
    "$$\\tilde{\\mu}(x_t,x_0)=\\frac{\\sqrt{\\alpha_t}(1-\\bar\\alpha_{t-1})}{1-\\bar\\alpha_t}x_t+\\frac{\\sqrt{\\bar\\alpha_{t-1}}\\beta_t}{1-\\bar\\alpha_t}x_0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed414315-8982-4a11-8c81-abbea2a53485",
   "metadata": {},
   "source": [
    "由预测噪声 $\\hat\\epsilon$ 得到 $$\\hat x_0=\\frac{1}{\\sqrt{\\bar\\alpha_t}}(x_t - \\sqrt{1-\\bar\\alpha_t}\\hat\\epsilon)$$\n",
    "\n",
    "带入上式，有：\n",
    "$${\\mu}(x_t,x_0)=\\frac{\\sqrt{\\alpha_t}(1-\\bar\\alpha_{t-1})}{1-\\bar\\alpha_t}x_t+\\frac{\\sqrt{\\bar\\alpha_{t-1}}\\beta_t}{1-\\bar\\alpha_t}\\hat x_0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2905e167-b311-4c84-b591-a18081109c75",
   "metadata": {},
   "source": [
    "### 2.3 隐状态空间"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aa17c3-0b68-431d-860e-3f8605937367",
   "metadata": {},
   "source": [
    "Latent Diffusion Model, LDM 就是让上述过程发生在隐状态空间内。[LDM](https://arxiv.org/pdf/2112.10752)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0bc28337-916f-4a5d-a1be-8ebcdc2558ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://towardsdatascience.com/wp-content/uploads/2022/09/1WTe5olMSFC-T6No0Y_gKWg.png\" width=\"600\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'https://towardsdatascience.com/wp-content/uploads/2022/09/1WTe5olMSFC-T6No0Y_gKWg.png'\n",
    "display(Image(url=url, width=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b021f293-5456-4cb4-85bb-f7ce331885b6",
   "metadata": {},
   "source": [
    "## 3. 简单实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b92778d6-da8f-4dd9-8a0e-010e94dc5499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torchinfo import summary\n",
    "import math\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ae8e6e49-5ae8-41cd-8b15-df40b5d1eec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data_path = 'data/MNIST/'\n",
    "image_size = 28\n",
    "batch_size = 128\n",
    "channels = 1\n",
    "timesteps = 1000\n",
    "latent_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "82ecb634-6e48-4ad7-b297-12fe605c5e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=[0.1307]\n",
    "std=[0.3081]\n",
    "def denormalize(tensor, mean, std):\n",
    "    mean = torch.tensor(mean).view(1, -1, 1, 1).to(tensor.device)\n",
    "    std = torch.tensor(std).view(1, -1, 1, 1).to(tensor.device)\n",
    "    return tensor * std + mean\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8065e12-64b2-4419-a800-d85dd8573013",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST(root='./data/', transform=transform, download='True', train=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e8c81437-ceb6-4951-ada1-39aa93210734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x200 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, _ = next(iter(dataloader))  # images: [B, 1, 28, 28]\n",
    "images = denormalize(images[:8], mean=[0.1307], std=[0.3081])\n",
    "# 去通道维度并绘图\n",
    "fig, axes = plt.subplots(1, 8, figsize=(12, 2))\n",
    "for i in range(8):\n",
    "    axes[i].imshow(images[i].squeeze(0).cpu(), cmap=\"gray\")\n",
    "    axes[i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2eca0e7-4e39-4d70-81fa-7f87869b0eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time embedding\n",
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(dim, dim * 4)\n",
    "        self.linear2 = nn.Linear(dim * 4, dim)\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "    def forward(self, t):\n",
    "        half_dim = self.linear1.in_features // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=t.device) * -emb)\n",
    "        emb = t[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return self.linear2(self.act(self.linear1(emb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a5ed695-d461-42fa-b6fc-07611071fb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual block with time embedding\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, time_emb_dim):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.GroupNorm(8, out_ch),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_emb_dim, out_ch)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.GroupNorm(8, out_ch),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "        self.residual = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
    "\n",
    "    def forward(self, x, t_emb):\n",
    "        h = self.block1(x)\n",
    "        h = h + self.time_mlp(t_emb)[:, :, None, None]\n",
    "        h = self.block2(h)\n",
    "        return h + self.residual(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "969a2998-5086-4e02-94da-38624d4ca924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-Attention block (for 2D images)\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.norm = nn.GroupNorm(8, channels)\n",
    "        self.q = nn.Conv1d(channels, channels, 1)\n",
    "        self.k = nn.Conv1d(channels, channels, 1)\n",
    "        self.v = nn.Conv1d(channels, channels, 1)\n",
    "        self.proj = nn.Conv1d(channels, channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        x_ = self.norm(x).view(B, C, H * W)  # [B, C, HW]\n",
    "        q, k, v = self.q(x_), self.k(x_), self.v(x_)\n",
    "\n",
    "        attn = torch.softmax(q.transpose(1, 2) @ k / math.sqrt(C), dim=-1)\n",
    "        out = v @ attn.transpose(1, 2)  # [B, C, HW]\n",
    "        out = self.proj(out).view(B, C, H, W)\n",
    "        return out + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b3717541-5022-4d77-8272-27f5f8dd3cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNet with Conv down/up and center attention\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, time_emb_dim=128):\n",
    "        super().__init__()\n",
    "        self.time_embedding = TimeEmbedding(time_emb_dim)\n",
    "\n",
    "        self.enc1 = ResBlock(1, 32, time_emb_dim)\n",
    "        self.down1 = nn.Conv2d(32, 64, 4, 2, 1)  # downsample\n",
    "        self.enc2 = ResBlock(64, 64, time_emb_dim)\n",
    "\n",
    "        self.mid = nn.Sequential(\n",
    "            ResBlock(64, 64, time_emb_dim),\n",
    "            AttentionBlock(64),\n",
    "            ResBlock(64, 64, time_emb_dim)\n",
    "        )\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(64, 32, 4, 2, 1)  # upsample\n",
    "        self.dec1 = ResBlock(32, 32, time_emb_dim)\n",
    "        self.out = nn.Conv2d(32, 1, 1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        t_emb = self.time_embedding(t)\n",
    "\n",
    "        x1 = self.enc1(x, t_emb)\n",
    "        x2 = self.enc2(self.down1(x1), t_emb)\n",
    "        \n",
    "        # 修改点：传递 t_emb 给 mid\n",
    "        x_mid = self.mid[0](x2, t_emb)  # ResBlock\n",
    "        x_mid = self.mid[1](x_mid)      # AttentionBlock\n",
    "        x_mid = self.mid[2](x_mid, t_emb)  # ResBlock\n",
    "\n",
    "        x_up = self.dec1(self.up1(x_mid), t_emb)\n",
    "        return self.out(x_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ade7e03d-58ca-43b3-a566-d64143bc5258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "# EMA Tracker\n",
    "class EMA:\n",
    "    def __init__(self, model, decay=0.9999):\n",
    "        self.model = deepcopy(model)\n",
    "        self.model.eval()\n",
    "        self.decay = decay\n",
    "\n",
    "    def update(self, model):\n",
    "        with torch.no_grad():\n",
    "            for p_ema, p in zip(self.model.parameters(), model.parameters()):\n",
    "                p_ema.data.mul_(self.decay).add_(p.data, alpha=1 - self.decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "118b93db-5311-4c1c-b5a4-8901a9d952cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 beta 调度器（线性或 cosine 可选）\n",
    "def make_beta_schedule(schedule='linear', timesteps=1000, s=0.008):\n",
    "    if schedule == 'linear':\n",
    "        beta_start = 1e-4\n",
    "        beta_end = 0.02\n",
    "        return torch.linspace(beta_start, beta_end, timesteps)\n",
    "    elif schedule == 'cosine':\n",
    "        steps = timesteps + 1\n",
    "        x = torch.linspace(0, timesteps, steps)\n",
    "        alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * np.pi * 0.5) ** 2\n",
    "        alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "        betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "        return torch.clip(betas, 0.0001, 0.9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f3097d72-0ce3-40c2-8c44-91dda803cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 扩散类\n",
    "class Diffusion:\n",
    "    def __init__(self, timesteps=1000, beta_schedule='cosine', device='cuda'):\n",
    "        self.timesteps = timesteps\n",
    "        self.betas = make_beta_schedule(beta_schedule, timesteps).to(device)\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alpha_hat = torch.cumprod(self.alphas, dim=0)\n",
    "        self.device = device\n",
    "\n",
    "    # q(x_t | x_0)\n",
    "    def q_sample(self, x_0, t, noise=None):\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x_0)\n",
    "        sqrt_alpha_hat = self.alpha_hat[t].sqrt().view(-1, 1, 1, 1)\n",
    "        sqrt_one_minus = (1 - self.alpha_hat[t]).sqrt().view(-1, 1, 1, 1)\n",
    "        return sqrt_alpha_hat * x_0 + sqrt_one_minus * noise\n",
    "\n",
    "    # 标准反向采样过程 p(x_{t-1} | x_t)\n",
    "    def p_sample(self, model, x, t):\n",
    "        beta_t = self.betas[t].view(-1, 1, 1, 1)\n",
    "        sqrt_one_minus_alpha = (1 - self.alpha_hat[t]).sqrt().view(-1, 1, 1, 1)\n",
    "        alpha_t = self.alphas[t].view(-1, 1, 1, 1)\n",
    "\n",
    "        eps_pred = model(x, t)\n",
    "        mean = (1 / alpha_t.sqrt()) * (x - (beta_t / sqrt_one_minus_alpha) * eps_pred)\n",
    "        noise = torch.randn_like(x) if (t > 0).all() else 0\n",
    "        return mean + noise * beta_t.sqrt()\n",
    "\n",
    "    # 完整采样流程\n",
    "    def p_sample_loop(self, model, shape):\n",
    "        x = torch.randn(shape).to(self.device)\n",
    "        for t in reversed(range(self.timesteps)):\n",
    "            t_batch = torch.full((shape[0],), t, device=self.device, dtype=torch.long)\n",
    "            x = self.p_sample(model, x, t_batch)\n",
    "        return x\n",
    "\n",
    "    # DDIM sampling（可调 eta）\n",
    "    def ddim_sample(self, model, shape, eta=0.0, steps=50):\n",
    "        times = torch.linspace(0, self.timesteps - 1, steps).long().to(self.device)\n",
    "        alphas = self.alpha_hat[times]\n",
    "\n",
    "        x = torch.randn(shape).to(self.device)\n",
    "\n",
    "        for i in reversed(range(steps)):\n",
    "            t = times[i].repeat(shape[0])\n",
    "            alpha = alphas[i].view(-1, 1, 1, 1)\n",
    "            eps = model(x, t)\n",
    "\n",
    "            x0_pred = (x - eps * (1 - alpha).sqrt()) / alpha.sqrt()\n",
    "            if i > 0:\n",
    "                alpha_prev = alphas[i - 1].view(-1, 1, 1, 1)\n",
    "                sigma = eta * ((1 - alpha_prev) / (1 - alpha) * (1 - alpha / alpha_prev)).sqrt()\n",
    "                noise = torch.randn_like(x)\n",
    "                x = alpha_prev.sqrt() * x0_pred + (1 - alpha_prev).sqrt() * eps + sigma * noise\n",
    "            else:\n",
    "                x = x0_pred\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "348018b3-7461-487f-84e6-8910a2b1e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化保存路径\n",
    "def save_samples(samples, step, path=\"./images/\"):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    save_image(samples, os.path.join(path, f\"{step:04d}.png\"), nrow=8, normalize=True)\n",
    "\n",
    "# 训练函数\n",
    "def train():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # 模型 & EMA\n",
    "    model = UNet().to(device)\n",
    "    ema = EMA(model)\n",
    "    diffusion = Diffusion(device=device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "\n",
    "    epochs = 400\n",
    "    for epoch in range(epochs):\n",
    "        pbar = tqdm.tqdm(dataloader, desc=f\"Epoch {epoch}\")\n",
    "        for i, (x, _) in enumerate(pbar):\n",
    "            x = x.to(device)\n",
    "            t = torch.randint(0, diffusion.timesteps, (x.size(0),), device=device).long()\n",
    "            noise = torch.randn_like(x)\n",
    "            x_t = diffusion.q_sample(x, t, noise)\n",
    "\n",
    "            loss = F.mse_loss(model(x_t, t), noise)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            ema.update(model)\n",
    "\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "        # 采样并保存\n",
    "        if epoch % 5 == 0:\n",
    "            with torch.no_grad():\n",
    "                samples = diffusion.p_sample_loop(ema.model, (64, 1, 28, 28))\n",
    "                samples = samples.clamp(0, 1)\n",
    "                samples = denormalize(samples, mean=[0.1307], std=[0.3081])\n",
    "                save_samples(samples, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dec9f23b-7ab5-4c4b-ba3f-1d92d3f5c3db",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████████████████████████████████████████████████████| 469/469 [00:22<00:00, 20.75it/s, loss=0.0862]\n",
      "Epoch 1: 100%|██████████████████████████████████████████████████████████| 469/469 [00:24<00:00, 19.37it/s, loss=0.0896]\n",
      "Epoch 2: 100%|██████████████████████████████████████████████████████████| 469/469 [00:23<00:00, 20.21it/s, loss=0.0636]\n",
      "Epoch 3: 100%|██████████████████████████████████████████████████████████| 469/469 [00:23<00:00, 19.79it/s, loss=0.0681]\n",
      "Epoch 4: 100%|██████████████████████████████████████████████████████████| 469/469 [00:24<00:00, 19.31it/s, loss=0.0674]\n",
      "Epoch 5: 100%|██████████████████████████████████████████████████████████| 469/469 [00:24<00:00, 18.79it/s, loss=0.0659]\n",
      "Epoch 6: 100%|██████████████████████████████████████████████████████████| 469/469 [00:25<00:00, 18.33it/s, loss=0.0578]\n",
      "Epoch 7: 100%|███████████████████████████████████████████████████████████| 469/469 [00:26<00:00, 17.94it/s, loss=0.069]\n",
      "Epoch 8: 100%|██████████████████████████████████████████████████████████| 469/469 [00:26<00:00, 17.80it/s, loss=0.0712]\n",
      "Epoch 9: 100%|██████████████████████████████████████████████████████████| 469/469 [00:26<00:00, 17.49it/s, loss=0.0644]\n",
      "Epoch 10: 100%|█████████████████████████████████████████████████████████| 469/469 [00:26<00:00, 17.40it/s, loss=0.0686]\n",
      "Epoch 11: 100%|█████████████████████████████████████████████████████████| 469/469 [00:27<00:00, 17.08it/s, loss=0.0464]\n",
      "Epoch 12: 100%|█████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.94it/s, loss=0.0551]\n",
      "Epoch 13: 100%|█████████████████████████████████████████████████████████| 469/469 [00:27<00:00, 16.84it/s, loss=0.0593]\n",
      "Epoch 14: 100%|█████████████████████████████████████████████████████████| 469/469 [00:27<00:00, 16.97it/s, loss=0.0566]\n",
      "Epoch 15: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.74it/s, loss=0.0629]\n",
      "Epoch 16: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.75it/s, loss=0.0571]\n",
      "Epoch 17: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.39it/s, loss=0.0566]\n",
      "Epoch 18: 100%|█████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.86it/s, loss=0.0551]\n",
      "Epoch 19: 100%|█████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.69it/s, loss=0.0554]\n",
      "Epoch 20: 100%|█████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.89it/s, loss=0.0524]\n",
      "Epoch 21: 100%|█████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.12it/s, loss=0.0549]\n",
      "Epoch 22: 100%|█████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.43it/s, loss=0.0627]\n",
      "Epoch 23: 100%|█████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.60it/s, loss=0.0493]\n",
      "Epoch 24: 100%|█████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.56it/s, loss=0.0532]\n",
      "Epoch 25: 100%|█████████████████████████████████████████████████████████| 469/469 [00:31<00:00, 14.96it/s, loss=0.0557]\n",
      "Epoch 26: 100%|█████████████████████████████████████████████████████████| 469/469 [00:32<00:00, 14.55it/s, loss=0.0596]\n",
      "Epoch 27: 100%|█████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.35it/s, loss=0.0527]\n",
      "Epoch 28: 100%|█████████████████████████████████████████████████████████| 469/469 [00:31<00:00, 14.83it/s, loss=0.0544]\n",
      "Epoch 29: 100%|█████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.32it/s, loss=0.0552]\n",
      "Epoch 30: 100%|█████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.48it/s, loss=0.0529]\n",
      "Epoch 31: 100%|█████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.66it/s, loss=0.0557]\n",
      "Epoch 32: 100%|██████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.38it/s, loss=0.049]\n",
      "Epoch 33: 100%|█████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.74it/s, loss=0.0583]\n",
      "Epoch 34: 100%|█████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.45it/s, loss=0.0519]\n",
      "Epoch 35: 100%|█████████████████████████████████████████████████████████| 469/469 [00:31<00:00, 15.00it/s, loss=0.0534]\n",
      "Epoch 36: 100%|█████████████████████████████████████████████████████████| 469/469 [00:31<00:00, 15.12it/s, loss=0.0535]\n",
      "Epoch 37: 100%|█████████████████████████████████████████████████████████| 469/469 [00:32<00:00, 14.42it/s, loss=0.0485]\n",
      "Epoch 38: 100%|█████████████████████████████████████████████████████████| 469/469 [00:31<00:00, 14.74it/s, loss=0.0575]\n",
      "Epoch 39: 100%|█████████████████████████████████████████████████████████| 469/469 [00:31<00:00, 15.06it/s, loss=0.0532]\n",
      "Epoch 40: 100%|█████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.54it/s, loss=0.0555]\n",
      "Epoch 41: 100%|█████████████████████████████████████████████████████████| 469/469 [00:31<00:00, 14.99it/s, loss=0.0651]\n",
      "Epoch 42: 100%|█████████████████████████████████████████████████████████| 469/469 [00:32<00:00, 14.30it/s, loss=0.0562]\n",
      "Epoch 43: 100%|█████████████████████████████████████████████████████████| 469/469 [00:31<00:00, 15.04it/s, loss=0.0569]\n",
      "Epoch 44: 100%|██████████████████████████████████████████████████████████| 469/469 [00:31<00:00, 15.06it/s, loss=0.058]\n",
      "Epoch 45: 100%|█████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.59it/s, loss=0.0574]\n",
      "Epoch 46: 100%|█████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.67it/s, loss=0.0579]\n",
      "Epoch 47: 100%|█████████████████████████████████████████████████████████| 469/469 [00:31<00:00, 14.75it/s, loss=0.0544]\n",
      "Epoch 48: 100%|█████████████████████████████████████████████████████████| 469/469 [00:32<00:00, 14.50it/s, loss=0.0545]\n",
      "Epoch 49: 100%|█████████████████████████████████████████████████████████| 469/469 [00:31<00:00, 14.82it/s, loss=0.0533]\n",
      "Epoch 50: 100%|█████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.52it/s, loss=0.0557]\n",
      "Epoch 51: 100%|█████████████████████████████████████████████████████████| 469/469 [00:32<00:00, 14.64it/s, loss=0.0485]\n",
      "Epoch 52: 100%|█████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.97it/s, loss=0.0513]\n",
      "Epoch 53: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.36it/s, loss=0.0555]\n",
      "Epoch 54: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.26it/s, loss=0.0463]\n",
      "Epoch 55: 100%|█████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.12it/s, loss=0.0512]\n",
      "Epoch 56: 100%|█████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.07it/s, loss=0.0527]\n",
      "Epoch 57: 100%|██████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.90it/s, loss=0.047]\n",
      "Epoch 58: 100%|█████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.12it/s, loss=0.0509]\n",
      "Epoch 59: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.18it/s, loss=0.0499]\n",
      "Epoch 60: 100%|█████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.65it/s, loss=0.0453]\n",
      "Epoch 61: 100%|█████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.97it/s, loss=0.0529]\n",
      "Epoch 62: 100%|█████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.97it/s, loss=0.0464]\n",
      "Epoch 63: 100%|█████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.39it/s, loss=0.0528]\n",
      "Epoch 64: 100%|██████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.72it/s, loss=0.051]\n",
      "Epoch 65: 100%|█████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.95it/s, loss=0.0498]\n",
      "Epoch 66: 100%|█████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.95it/s, loss=0.0565]\n",
      "Epoch 67: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.28it/s, loss=0.0532]\n",
      "Epoch 68: 100%|█████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.39it/s, loss=0.0536]\n",
      "Epoch 69: 100%|█████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.95it/s, loss=0.0459]\n",
      "Epoch 70: 100%|█████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.25it/s, loss=0.0465]\n",
      "Epoch 71: 100%|█████████████████████████████████████████████████████████| 469/469 [00:31<00:00, 14.93it/s, loss=0.0599]\n",
      "Epoch 72: 100%|█████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.90it/s, loss=0.0445]\n",
      "Epoch 73: 100%|█████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.45it/s, loss=0.0485]\n",
      "Epoch 74: 100%|█████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.06it/s, loss=0.0503]\n",
      "Epoch 75: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.48it/s, loss=0.0506]\n",
      "Epoch 76: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.52it/s, loss=0.0534]\n",
      "Epoch 77: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.52it/s, loss=0.0497]\n",
      "Epoch 78: 100%|██████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.32it/s, loss=0.047]\n",
      "Epoch 79: 100%|██████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.16it/s, loss=0.047]\n",
      "Epoch 80: 100%|█████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.28it/s, loss=0.0554]\n",
      "Epoch 81: 100%|█████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.82it/s, loss=0.0413]\n",
      "Epoch 82: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.34it/s, loss=0.0533]\n",
      "Epoch 83: 100%|██████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.50it/s, loss=0.054]\n",
      "Epoch 84: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.39it/s, loss=0.0529]\n",
      "Epoch 85: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.43it/s, loss=0.0534]\n",
      "Epoch 86: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.48it/s, loss=0.0504]\n",
      "Epoch 87: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.45it/s, loss=0.0458]\n",
      "Epoch 88: 100%|█████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.98it/s, loss=0.0517]\n",
      "Epoch 89: 100%|█████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.83it/s, loss=0.0509]\n",
      "Epoch 90: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.28it/s, loss=0.0518]\n",
      "Epoch 91: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.27it/s, loss=0.0522]\n",
      "Epoch 92: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.34it/s, loss=0.0508]\n",
      "Epoch 93: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.28it/s, loss=0.0511]\n",
      "Epoch 94: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.35it/s, loss=0.0502]\n",
      "Epoch 95: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.32it/s, loss=0.0502]\n",
      "Epoch 96: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.34it/s, loss=0.0503]\n",
      "Epoch 97: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.46it/s, loss=0.0445]\n",
      "Epoch 98: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.47it/s, loss=0.0541]\n",
      "Epoch 99: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.46it/s, loss=0.0523]\n",
      "Epoch 100: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.47it/s, loss=0.0442]\n",
      "Epoch 101: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.43it/s, loss=0.0531]\n",
      "Epoch 102: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.50it/s, loss=0.0513]\n",
      "Epoch 103: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.54it/s, loss=0.0479]\n",
      "Epoch 104: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.31it/s, loss=0.0505]\n",
      "Epoch 105: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.30it/s, loss=0.0509]\n",
      "Epoch 106: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.22it/s, loss=0.0512]\n",
      "Epoch 107: 100%|████████████████████████████████████████████████████████| 469/469 [00:31<00:00, 14.82it/s, loss=0.0551]\n",
      "Epoch 108: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.35it/s, loss=0.0503]\n",
      "Epoch 109: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.43it/s, loss=0.0456]\n",
      "Epoch 110: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.54it/s, loss=0.0453]\n",
      "Epoch 111: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.46it/s, loss=0.0421]\n",
      "Epoch 112: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.47it/s, loss=0.0493]\n",
      "Epoch 113: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.48it/s, loss=0.0504]\n",
      "Epoch 114: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.39it/s, loss=0.0491]\n",
      "Epoch 115: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.49it/s, loss=0.0483]\n",
      "Epoch 116: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.44it/s, loss=0.0541]\n",
      "Epoch 117: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.53it/s, loss=0.0551]\n",
      "Epoch 118: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.53it/s, loss=0.0493]\n",
      "Epoch 119: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.51it/s, loss=0.0492]\n",
      "Epoch 120: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.52it/s, loss=0.0459]\n",
      "Epoch 121: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.49it/s, loss=0.0486]\n",
      "Epoch 122: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.54it/s, loss=0.0465]\n",
      "Epoch 123: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.62it/s, loss=0.0483]\n",
      "Epoch 124: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.35it/s, loss=0.049]\n",
      "Epoch 125: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.43it/s, loss=0.0428]\n",
      "Epoch 126: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.39it/s, loss=0.0437]\n",
      "Epoch 127: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.27it/s, loss=0.0509]\n",
      "Epoch 128: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.30it/s, loss=0.0523]\n",
      "Epoch 129: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.47it/s, loss=0.0537]\n",
      "Epoch 130: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.41it/s, loss=0.0495]\n",
      "Epoch 131: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.31it/s, loss=0.0494]\n",
      "Epoch 132: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.51it/s, loss=0.0437]\n",
      "Epoch 133: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.36it/s, loss=0.0541]\n",
      "Epoch 134: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.14it/s, loss=0.0489]\n",
      "Epoch 135: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.42it/s, loss=0.0574]\n",
      "Epoch 136: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.85it/s, loss=0.0533]\n",
      "Epoch 137: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.39it/s, loss=0.0499]\n",
      "Epoch 138: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.43it/s, loss=0.0516]\n",
      "Epoch 139: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.47it/s, loss=0.0537]\n",
      "Epoch 140: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.52it/s, loss=0.0512]\n",
      "Epoch 141: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.25it/s, loss=0.0459]\n",
      "Epoch 142: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.40it/s, loss=0.0544]\n",
      "Epoch 143: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.45it/s, loss=0.049]\n",
      "Epoch 144: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.37it/s, loss=0.0458]\n",
      "Epoch 145: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.51it/s, loss=0.0485]\n",
      "Epoch 146: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.44it/s, loss=0.0522]\n",
      "Epoch 147: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.57it/s, loss=0.0483]\n",
      "Epoch 148: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.54it/s, loss=0.0495]\n",
      "Epoch 149: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.50it/s, loss=0.0508]\n",
      "Epoch 150: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.48it/s, loss=0.0517]\n",
      "Epoch 151: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.47it/s, loss=0.0471]\n",
      "Epoch 152: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.46it/s, loss=0.0435]\n",
      "Epoch 153: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.41it/s, loss=0.0517]\n",
      "Epoch 154: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.44it/s, loss=0.0477]\n",
      "Epoch 155: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.47it/s, loss=0.0539]\n",
      "Epoch 156: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.50it/s, loss=0.046]\n",
      "Epoch 157: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.45it/s, loss=0.0489]\n",
      "Epoch 158: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.37it/s, loss=0.0496]\n",
      "Epoch 159: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.36it/s, loss=0.0489]\n",
      "Epoch 160: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.41it/s, loss=0.0441]\n",
      "Epoch 161: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.53it/s, loss=0.0493]\n",
      "Epoch 162: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.39it/s, loss=0.0515]\n",
      "Epoch 163: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.45it/s, loss=0.0512]\n",
      "Epoch 164: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.39it/s, loss=0.0546]\n",
      "Epoch 165: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.46it/s, loss=0.0523]\n",
      "Epoch 166: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.51it/s, loss=0.0451]\n",
      "Epoch 167: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.50it/s, loss=0.0503]\n",
      "Epoch 168: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.23it/s, loss=0.044]\n",
      "Epoch 169: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.44it/s, loss=0.0372]\n",
      "Epoch 170: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.44it/s, loss=0.047]\n",
      "Epoch 171: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.48it/s, loss=0.0507]\n",
      "Epoch 172: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.42it/s, loss=0.0418]\n",
      "Epoch 173: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.41it/s, loss=0.036]\n",
      "Epoch 174: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.35it/s, loss=0.0449]\n",
      "Epoch 175: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.44it/s, loss=0.0491]\n",
      "Epoch 176: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.47it/s, loss=0.048]\n",
      "Epoch 177: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.43it/s, loss=0.0481]\n",
      "Epoch 178: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.44it/s, loss=0.052]\n",
      "Epoch 179: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.50it/s, loss=0.0549]\n",
      "Epoch 180: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.46it/s, loss=0.0469]\n",
      "Epoch 181: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.45it/s, loss=0.0456]\n",
      "Epoch 182: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.40it/s, loss=0.0501]\n",
      "Epoch 183: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.39it/s, loss=0.0493]\n",
      "Epoch 184: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.34it/s, loss=0.0562]\n",
      "Epoch 185: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.30it/s, loss=0.0445]\n",
      "Epoch 186: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.36it/s, loss=0.0483]\n",
      "Epoch 187: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.35it/s, loss=0.0452]\n",
      "Epoch 188: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.40it/s, loss=0.0514]\n",
      "Epoch 189: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.39it/s, loss=0.0445]\n",
      "Epoch 190: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.43it/s, loss=0.047]\n",
      "Epoch 191: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.44it/s, loss=0.0454]\n",
      "Epoch 192: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.44it/s, loss=0.043]\n",
      "Epoch 193: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.47it/s, loss=0.0472]\n",
      "Epoch 194: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.35it/s, loss=0.0424]\n",
      "Epoch 195: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.47it/s, loss=0.0452]\n",
      "Epoch 196: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.42it/s, loss=0.0393]\n",
      "Epoch 197: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.51it/s, loss=0.0495]\n",
      "Epoch 198: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.32it/s, loss=0.0474]\n",
      "Epoch 199: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.36it/s, loss=0.0533]\n",
      "Epoch 200: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.29it/s, loss=0.0496]\n",
      "Epoch 201: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.50it/s, loss=0.0494]\n",
      "Epoch 202: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.41it/s, loss=0.0381]\n",
      "Epoch 203: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.30it/s, loss=0.0501]\n",
      "Epoch 204: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.30it/s, loss=0.0437]\n",
      "Epoch 205: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.28it/s, loss=0.0534]\n",
      "Epoch 206: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.90it/s, loss=0.0512]\n",
      "Epoch 207: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.34it/s, loss=0.0465]\n",
      "Epoch 208: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.44it/s, loss=0.0447]\n",
      "Epoch 209: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.45it/s, loss=0.0442]\n",
      "Epoch 210: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.39it/s, loss=0.0499]\n",
      "Epoch 211: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.41it/s, loss=0.0517]\n",
      "Epoch 212: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.44it/s, loss=0.0532]\n",
      "Epoch 213: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.33it/s, loss=0.0493]\n",
      "Epoch 214: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.37it/s, loss=0.0421]\n",
      "Epoch 215: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.47it/s, loss=0.0445]\n",
      "Epoch 216: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.50it/s, loss=0.0515]\n",
      "Epoch 217: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.40it/s, loss=0.0526]\n",
      "Epoch 218: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.45it/s, loss=0.0433]\n",
      "Epoch 219: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.34it/s, loss=0.0487]\n",
      "Epoch 220: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.33it/s, loss=0.046]\n",
      "Epoch 221: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.44it/s, loss=0.0498]\n",
      "Epoch 222: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.36it/s, loss=0.0498]\n",
      "Epoch 223: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.42it/s, loss=0.0559]\n",
      "Epoch 224: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.50it/s, loss=0.0476]\n",
      "Epoch 225: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.08it/s, loss=0.0519]\n",
      "Epoch 226: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.05it/s, loss=0.0464]\n",
      "Epoch 227: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.42it/s, loss=0.0486]\n",
      "Epoch 228: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.39it/s, loss=0.0531]\n",
      "Epoch 229: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.34it/s, loss=0.0496]\n",
      "Epoch 230: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.44it/s, loss=0.048]\n",
      "Epoch 231: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.42it/s, loss=0.0452]\n",
      "Epoch 232: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.44it/s, loss=0.0431]\n",
      "Epoch 233: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.40it/s, loss=0.0491]\n",
      "Epoch 234: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.46it/s, loss=0.0507]\n",
      "Epoch 235: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.36it/s, loss=0.0472]\n",
      "Epoch 236: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.38it/s, loss=0.0429]\n",
      "Epoch 237: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.39it/s, loss=0.0505]\n",
      "Epoch 238: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.37it/s, loss=0.0461]\n",
      "Epoch 239: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.29it/s, loss=0.0467]\n",
      "Epoch 240: 100%|████████████████████████████████████████████████████████| 469/469 [00:33<00:00, 14.04it/s, loss=0.0522]\n",
      "Epoch 241: 100%|█████████████████████████████████████████████████████████| 469/469 [00:31<00:00, 15.08it/s, loss=0.044]\n",
      "Epoch 242: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.16it/s, loss=0.0502]\n",
      "Epoch 243: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.27it/s, loss=0.0499]\n",
      "Epoch 244: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.28it/s, loss=0.0514]\n",
      "Epoch 245: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.33it/s, loss=0.0456]\n",
      "Epoch 246: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.39it/s, loss=0.0433]\n",
      "Epoch 247: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.47it/s, loss=0.0542]\n",
      "Epoch 248: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.29it/s, loss=0.0501]\n",
      "Epoch 249: 100%|████████████████████████████████████████████████████████| 469/469 [00:31<00:00, 14.88it/s, loss=0.0453]\n",
      "Epoch 250: 100%|████████████████████████████████████████████████████████| 469/469 [00:38<00:00, 12.31it/s, loss=0.0417]\n",
      "Epoch 251: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.28it/s, loss=0.0503]\n",
      "Epoch 252: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.40it/s, loss=0.0455]\n",
      "Epoch 253: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.40it/s, loss=0.0479]\n",
      "Epoch 254: 100%|█████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.40it/s, loss=0.047]\n",
      "Epoch 255: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.46it/s, loss=0.0473]\n",
      "Epoch 256: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.45it/s, loss=0.0466]\n",
      "Epoch 257: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.20it/s, loss=0.0471]\n",
      "Epoch 258: 100%|█████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.53it/s, loss=0.051]\n",
      "Epoch 259: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.38it/s, loss=0.0434]\n",
      "Epoch 260: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.42it/s, loss=0.0512]\n",
      "Epoch 261: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.55it/s, loss=0.0498]\n",
      "Epoch 262: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.46it/s, loss=0.0506]\n",
      "Epoch 263: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.18it/s, loss=0.0462]\n",
      "Epoch 264: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.19it/s, loss=0.0488]\n",
      "Epoch 265: 100%|████████████████████████████████████████████████████████| 469/469 [00:32<00:00, 14.63it/s, loss=0.0453]\n",
      "Epoch 266: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.31it/s, loss=0.0478]\n",
      "Epoch 267: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.39it/s, loss=0.0418]\n",
      "Epoch 268: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.24it/s, loss=0.0469]\n",
      "Epoch 269: 100%|█████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.26it/s, loss=0.047]\n",
      "Epoch 270: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.22it/s, loss=0.0463]\n",
      "Epoch 271: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.21it/s, loss=0.0429]\n",
      "Epoch 272: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.26it/s, loss=0.0385]\n",
      "Epoch 273: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.28it/s, loss=0.0506]\n",
      "Epoch 274: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.30it/s, loss=0.0475]\n",
      "Epoch 275: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.24it/s, loss=0.0507]\n",
      "Epoch 276: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.39it/s, loss=0.0542]\n",
      "Epoch 277: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.19it/s, loss=0.0425]\n",
      "Epoch 278: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.27it/s, loss=0.0511]\n",
      "Epoch 279: 100%|█████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.26it/s, loss=0.049]\n",
      "Epoch 280: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.33it/s, loss=0.0534]\n",
      "Epoch 281: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.22it/s, loss=0.0485]\n",
      "Epoch 282: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.20it/s, loss=0.0416]\n",
      "Epoch 283: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.26it/s, loss=0.0494]\n",
      "Epoch 284: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.26it/s, loss=0.0472]\n",
      "Epoch 285: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.36it/s, loss=0.0467]\n",
      "Epoch 286: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.37it/s, loss=0.0473]\n",
      "Epoch 287: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.33it/s, loss=0.0464]\n",
      "Epoch 288: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.26it/s, loss=0.0427]\n",
      "Epoch 289: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.16it/s, loss=0.0447]\n",
      "Epoch 290: 100%|█████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.27it/s, loss=0.048]\n",
      "Epoch 291: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.19it/s, loss=0.0479]\n",
      "Epoch 292: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.35it/s, loss=0.0466]\n",
      "Epoch 293: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.44it/s, loss=0.0444]\n",
      "Epoch 294: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.42it/s, loss=0.0484]\n",
      "Epoch 295: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.35it/s, loss=0.0492]\n",
      "Epoch 296: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.43it/s, loss=0.0518]\n",
      "Epoch 297: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.43it/s, loss=0.0424]\n",
      "Epoch 298: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.41it/s, loss=0.0533]\n",
      "Epoch 299: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.37it/s, loss=0.0474]\n",
      "Epoch 300: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.37it/s, loss=0.0491]\n",
      "Epoch 301: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.41it/s, loss=0.0447]\n",
      "Epoch 302: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.41it/s, loss=0.049]\n",
      "Epoch 303: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.30it/s, loss=0.0524]\n",
      "Epoch 304: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.40it/s, loss=0.0421]\n",
      "Epoch 305: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.35it/s, loss=0.0458]\n",
      "Epoch 306: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.37it/s, loss=0.0528]\n",
      "Epoch 307: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.36it/s, loss=0.0455]\n",
      "Epoch 308: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.47it/s, loss=0.0473]\n",
      "Epoch 309: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.37it/s, loss=0.0393]\n",
      "Epoch 310: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.88it/s, loss=0.0481]\n",
      "Epoch 311: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.10it/s, loss=0.0386]\n",
      "Epoch 312: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.33it/s, loss=0.0497]\n",
      "Epoch 313: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.30it/s, loss=0.0448]\n",
      "Epoch 314: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.21it/s, loss=0.0378]\n",
      "Epoch 315: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.29it/s, loss=0.0506]\n",
      "Epoch 316: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.30it/s, loss=0.0521]\n",
      "Epoch 317: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.04it/s, loss=0.0505]\n",
      "Epoch 318: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.39it/s, loss=0.0481]\n",
      "Epoch 319: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.33it/s, loss=0.0501]\n",
      "Epoch 320: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.30it/s, loss=0.0449]\n",
      "Epoch 321: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.19it/s, loss=0.0461]\n",
      "Epoch 322: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.18it/s, loss=0.0494]\n",
      "Epoch 323: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.21it/s, loss=0.0449]\n",
      "Epoch 324: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.26it/s, loss=0.0461]\n",
      "Epoch 325: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.28it/s, loss=0.0496]\n",
      "Epoch 326: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.38it/s, loss=0.0445]\n",
      "Epoch 327: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.31it/s, loss=0.0471]\n",
      "Epoch 328: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.25it/s, loss=0.0494]\n",
      "Epoch 329: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.37it/s, loss=0.0427]\n",
      "Epoch 330: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.36it/s, loss=0.0499]\n",
      "Epoch 331: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.26it/s, loss=0.0492]\n",
      "Epoch 332: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.21it/s, loss=0.0468]\n",
      "Epoch 333: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.17it/s, loss=0.0495]\n",
      "Epoch 334: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.35it/s, loss=0.0508]\n",
      "Epoch 335: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.36it/s, loss=0.0508]\n",
      "Epoch 336: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.31it/s, loss=0.0435]\n",
      "Epoch 337: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.27it/s, loss=0.0487]\n",
      "Epoch 338: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.20it/s, loss=0.0481]\n",
      "Epoch 339: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.20it/s, loss=0.0434]\n",
      "Epoch 340: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.27it/s, loss=0.0416]\n",
      "Epoch 341: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.40it/s, loss=0.0452]\n",
      "Epoch 342: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.24it/s, loss=0.0501]\n",
      "Epoch 343: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.30it/s, loss=0.0421]\n",
      "Epoch 344: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.33it/s, loss=0.047]\n",
      "Epoch 345: 100%|██████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.20it/s, loss=0.05]\n",
      "Epoch 346: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.31it/s, loss=0.0465]\n",
      "Epoch 347: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.14it/s, loss=0.0527]\n",
      "Epoch 348: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.25it/s, loss=0.0486]\n",
      "Epoch 349: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.27it/s, loss=0.051]\n",
      "Epoch 350: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.29it/s, loss=0.046]\n",
      "Epoch 351: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.24it/s, loss=0.0436]\n",
      "Epoch 352: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.29it/s, loss=0.0475]\n",
      "Epoch 353: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.29it/s, loss=0.0445]\n",
      "Epoch 354: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.33it/s, loss=0.0496]\n",
      "Epoch 355: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.35it/s, loss=0.0553]\n",
      "Epoch 356: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.37it/s, loss=0.0482]\n",
      "Epoch 357: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.40it/s, loss=0.046]\n",
      "Epoch 358: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.19it/s, loss=0.0558]\n",
      "Epoch 359: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.29it/s, loss=0.0405]\n",
      "Epoch 360: 100%|█████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.25it/s, loss=0.049]\n",
      "Epoch 361: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.25it/s, loss=0.0469]\n",
      "Epoch 362: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.27it/s, loss=0.0467]\n",
      "Epoch 363: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.19it/s, loss=0.0494]\n",
      "Epoch 364: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.28it/s, loss=0.0555]\n",
      "Epoch 365: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.08it/s, loss=0.0494]\n",
      "Epoch 366: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.30it/s, loss=0.0472]\n",
      "Epoch 367: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.21it/s, loss=0.0472]\n",
      "Epoch 368: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.13it/s, loss=0.0511]\n",
      "Epoch 369: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.24it/s, loss=0.0459]\n",
      "Epoch 370: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.28it/s, loss=0.0476]\n",
      "Epoch 371: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.33it/s, loss=0.0465]\n",
      "Epoch 372: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.25it/s, loss=0.0507]\n",
      "Epoch 373: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.21it/s, loss=0.0427]\n",
      "Epoch 374: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.98it/s, loss=0.0462]\n",
      "Epoch 375: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.21it/s, loss=0.0402]\n",
      "Epoch 376: 100%|█████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.13it/s, loss=0.046]\n",
      "Epoch 377: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.08it/s, loss=0.0467]\n",
      "Epoch 378: 100%|████████████████████████████████████████████████████████| 469/469 [00:30<00:00, 15.62it/s, loss=0.0434]\n",
      "Epoch 379: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.16it/s, loss=0.0446]\n",
      "Epoch 380: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.16it/s, loss=0.0449]\n",
      "Epoch 381: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.13it/s, loss=0.0509]\n",
      "Epoch 382: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.11it/s, loss=0.0448]\n",
      "Epoch 383: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.15it/s, loss=0.0422]\n",
      "Epoch 384: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.15it/s, loss=0.0456]\n",
      "Epoch 385: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.93it/s, loss=0.0464]\n",
      "Epoch 386: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.14it/s, loss=0.0419]\n",
      "Epoch 387: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.00it/s, loss=0.0517]\n",
      "Epoch 388: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.07it/s, loss=0.0438]\n",
      "Epoch 389: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.07it/s, loss=0.0485]\n",
      "Epoch 390: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.17it/s, loss=0.0446]\n",
      "Epoch 391: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.86it/s, loss=0.0396]\n",
      "Epoch 392: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.10it/s, loss=0.0427]\n",
      "Epoch 393: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.84it/s, loss=0.0493]\n",
      "Epoch 394: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 15.78it/s, loss=0.0414]\n",
      "Epoch 395: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.06it/s, loss=0.0448]\n",
      "Epoch 396: 100%|████████████████████████████████████████████████████████| 469/469 [00:29<00:00, 16.12it/s, loss=0.0475]\n",
      "Epoch 397: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.27it/s, loss=0.0538]\n",
      "Epoch 398: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.20it/s, loss=0.0508]\n",
      "Epoch 399: 100%|████████████████████████████████████████████████████████| 469/469 [00:28<00:00, 16.28it/s, loss=0.0504]\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ffcc82bf-2eb0-4a91-a7be-505c5e00a748",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'ema_state_dict': ema.model.state_dict(), \n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': 400\n",
    "}, './model_pkl/mnist_diffusion_final.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1102b3e0-0cac-46e5-86a8-1b58f576a20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存多个中间步骤图像\n",
    "def visualize_denoising(diffusion, model, shape, save_dir=\"./images\", steps=20):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    x = torch.randn(shape).to(diffusion.device)\n",
    "    indices = torch.linspace(0, diffusion.timesteps - 1, steps).long()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, t in enumerate(reversed(indices)):\n",
    "            t_batch = torch.full((shape[0],), t.item(), dtype=torch.long).to(diffusion.device)\n",
    "            x = diffusion.p_sample(model, x, t_batch)\n",
    "            out = (x.clamp(-1, 1) + 1) / 2\n",
    "            out = denormalize(out, mean, std)\n",
    "            save_image(out, os.path.join(save_dir, f\"step_{i:02d}.png\"), nrow=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeab420-80e3-4cb4-a062-89579bd0fbf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "069e6fff-42dc-4506-be44-0a88cd8b4eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet().to(device)\n",
    "ema = EMA(model, decay=0.9999)\n",
    "checkpoint = torch.load('./model_pkl/mnist_diffusion_final.pth', map_location='cpu', weights_only=False)\n",
    "ema.model.load_state_dict(checkpoint['ema_state_dict'])\n",
    "ema.model.eval()\n",
    "diffusion = Diffusion(timesteps=1000, beta_schedule='cosine', device='cuda')\n",
    "visualize_denoising(diffusion, ema.model, (64, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c828e7a7-7b05-4a0c-bc2d-ba7a2f57097a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
