{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa467b57-a9f7-41e0-a4a4-71f158a58a75",
   "metadata": {},
   "source": [
    "## 1. Transformer\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedbe633-3296-4ae7-8c31-b9d021fb07ac",
   "metadata": {},
   "source": [
    "大名鼎鼎，论文地址：[Transformer](https://arxiv.org/pdf/1706.03762)\n",
    "\n",
    "实现了深度循环神经网络并行计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c9cbcb6-bba8-4f75-9db3-6ede25a0e14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://theaisummer.com/static/6122618d7e1466853e88473ba375cdc7/40ffe/transformer.png\" width=\"600\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "url = 'https://theaisummer.com/static/6122618d7e1466853e88473ba375cdc7/40ffe/transformer.png'\n",
    "display(Image(url=url, width=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71349dcd-223f-42a1-a3f2-ce603db4f544",
   "metadata": {},
   "source": [
    "## 2. 数学过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8f36c0-a264-4ff4-b87b-bfacff034e33",
   "metadata": {},
   "source": [
    "### 2.1 编码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ed89c7-90de-4942-b1d3-18241756d3ea",
   "metadata": {},
   "source": [
    "分两步：\n",
    "\n",
    "**1. 词嵌入（Input & Embedding）**\n",
    "\n",
    "字典大小 vocab_size × embed_dim\n",
    "\n",
    "词大小 1 × embed_dim\n",
    "    \n",
    "句子大小 seq_len × embed_dim\n",
    "\n",
    "批量句子大小 batch_size × seq_len × embed_dim\n",
    "\n",
    "**2. 位置编码（Positional Encoding）**\n",
    "\n",
    "由于 Transformer 的自注意力机制本身不具备对输入顺序的感知能力，位置编码在 Transformer 架构中引入序列位置信息。\n",
    "\n",
    "为每个位置生成唯一的编码向量，直接加到词嵌入上。\n",
    "\n",
    "位置编码数学公式，根据位置p、维度i、词嵌入维度d, 偶数维和奇数维交替使用正弦和余弦。\n",
    "\n",
    "正弦：$PE_{(p, i, d)}=\\sin(\\frac{p}{10000^{2i/d}})$\n",
    "\n",
    "余弦：$PE_{(p, i, d)}=\\cos(\\frac{p}{10000^{2i/d}})$\n",
    "\n",
    "矩阵大小 seq_len × embed_dim\n",
    "\n",
    "批量大小 batch_size × seq_len × embed_dim\n",
    "\n",
    "**3. 编码结果**\n",
    "\n",
    "X = E + P\n",
    "\n",
    "批量维度 batch_size × seq_len × embed_dim\n",
    "\n",
    "**4. 位置编码的讨论**\n",
    "\n",
    "上面采用正弦和余弦公式是原始论文中所采用的方式。  \n",
    "存在的主要问题是，位置编码的公式是固定的，不可学习，而且在最后采用将位置编码直接加到词向量上，污染了信息。  \n",
    "随着研究的深入，旋转位置嵌入（Rotary Positional Embedding, RoPE）的模式得到很大关注。这里有篇论文。[RoPE](https://arxiv.org/pdf/2410.06205)  \n",
    "原始的位置编码，从开始可以看作是一种二进制的方波，但因为跳跃变化，采用了类似正弦余弦波的编码方式。  \n",
    "下面总结一下个人看法：  \n",
    "（1）词嵌入是没有位置关系的，也没有多重语义，但的确编码了大部分语言符号的意思的差异。我将之成为全局性语义向量（Global Semantic Vector）。之所以这么称呼的原因是因为，词嵌入更多的表达的是一种数据转换，将语言符号转换为数字。全局性语义向量，一方面是从更加自然性的语言角度理解，另一方面表示词汇在语义空间上的向量表达。  \n",
    "（2）词汇之间的位置关系和语义关联，是和使用词汇的场景是高度关联的。如果我们将之称为局部语义空间，那么位置编码可以看作是是从全局性语义向量向局部语义向量（Local Semantic Vector）做的一个映射，映射后的局部语义向量看作是上下文中词汇语义的真实表达。  \n",
    "（3）当然在操作上，我们希望这个映射是线性的。而且，如果上下文中的某些位置关联紧密，那么它们之间的局部语义向量之间应该有更高的余弦相似度。于是，位置p的向量V(p)可以经由某个矩阵变换M得到p+k位置的相似向量V(p+k)。可参见[RoFormer论文](https://arxiv.org/pdf/2104.09864)  \n",
    "（4）最终结果是通过矩阵乘法的形式（实际上采用的是克式积），实现了由全局性语义空间向局部语义空间的映射。避免了加法带来的语义污染，并且具有了科学系的特征。  \n",
    "（5）编码可以看作两步：词汇符号→全局语义向量→局部语义向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a450937-1c18-4f4e-a235-88ca85a12acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1b8b760a150>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 经典PE的数值分布\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def pe(seq_len, embed_dim):\n",
    "    L = []\n",
    "    for i in range(seq_len):\n",
    "        if i%2==0:\n",
    "            L.append(round(np.cos(seq_len/(10000**(2*i/embed_dim))),4))\n",
    "        else:\n",
    "            L.append(round(np.sin(seq_len/(10000**(2*i/embed_dim))),4))\n",
    "    return L\n",
    "L = pe(521, 256)\n",
    "C = [x % 2 for x in range(len(L)) ]\n",
    "plt.scatter(x=np.arange(len(L)), y=L, s=3, c=C, cmap='Paired')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd8b170-b79e-4bb7-aa6d-5b6a3ea6a4c4",
   "metadata": {},
   "source": [
    "### 2.2 注意力机制"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f99ca2-a864-4111-a286-b161b5bcd2db",
   "metadata": {},
   "source": [
    "注意力机制有很多变体。  \n",
    "这里按照逐层深入的方式，拆解为：单头注意力、多头注意力、掩码多头注意力、交叉多头注意力。  \n",
    "后续优化变体多查询注意力(MQA)，分组查询注意力(GQA)，多潜头注意力(MLA)。  \n",
    "\n",
    "厘清维度+理解作用是关键。 \n",
    "先定义一些超参数，方便后面理解  \n",
    "vocab_size：词表大小（一般为50000左右）。字母：V  \n",
    "embed_dim：词向量维度。字母 C  \n",
    "batch_size：批量大小。字母 B  \n",
    "seq_len：上下文长度。字母 T  \n",
    "num_heads：注意力头的数量。字母 n  \n",
    "single_head_dim：单个注意力头的维数。字母 s  \n",
    "multi_head_dim = single_head_dim × num_heads：多头注意力维数，一般等于embed_dim。字母 H  \n",
    "\n",
    "Attention最著名的公式：$$\\mathbf{Attention}(Q, K, V)=\\mathbf{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V $$\n",
    "\n",
    "里面涉及三个重要的向量Q, K, V, 分别代表查询（Query）、键（Key）和值（Value）。  \n",
    "Transformer左边是编码器，右边是解码器。编码器最终输出K, V用于右边的解码器，而解码器用自身的Q。  \n",
    "所以查询的意思是容易理解的。  \n",
    "再看公式的最后，是关于V的某个线性组合，所以值的意思也清楚。\n",
    "键的意思是作为参考而言的。\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4a3d85-964d-4e57-a8ff-cc30fc66116b",
   "metadata": {},
   "source": [
    "下面是**单头注意力**的维度变化情况：  \n",
    "1. 输入X的维度是(B, T, C)，复制三份。\n",
    "2. 与查询矩阵$W_Q$作用，得到Q。即X经过$W_Q$线性变换得到Q。$W_Q$的维度是(B, C, H)，Q的维度是(B, T, H)\n",
    ">如是线性变换，按照矩阵乘法，$W_Q$应该在X的左边，即$XW_Q$，但很多论文和研究报告，都把X写在左边，这主要是因为在变换之后，X的C维度会消失，写在左边符合矩阵乘法的直觉，但在变换的视角下又是别扭的，这归功于pytorch在维度处理上的优秀设计。\n",
    "\n",
    "3. 同样的有键矩阵$W_K$，作用在X上。$W_K$的维度是(B, C, H)，K的维度是(B, T, H)\n",
    "4. 进行点积+缩放操作，即 $\\frac{QK^T}{\\sqrt{d_k}}$，结果维度是(B, T, T)\n",
    ">上述操作将输入X经过线性变化从原来的(B, T, C)变换到(B, T, H)空间进行表示。\n",
    ">点积操作是为了比较一个序列中，各位置上元素的距离，可以用余弦相似度来理解\n",
    ">缩放是出于数值稳定性的考虑，其中$d_k$是每个头的维度，但单头注意力中等于H\n",
    "\n",
    "5. softmax使其称为一个概率分布，注意力权重矩阵，torch中是每一行，矩阵乘法中是每一列\n",
    "6. 有值矩阵$W_V$，作用在X上。$W_V$的维度是(B, C, H)，V的维度是(B, T, H)\n",
    "7. 将权重矩阵和V相乘，得到结果，维度是(B, T, H)，与输入维度一致。注：在多元线性回归中，我们一般是将权重写在右侧的，如$||Y-Xw-b||^2$，其中$w$是权重\n",
    "8. 残差连接\n",
    "9. 层归一化，沿最后一维归一化。\n",
    "10. 再接前馈神经网络或混合专家模型。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89669ce1-334b-4723-9db5-1524db3f1d85",
   "metadata": {},
   "source": [
    "**多头注意力**，在计算出Q,K,V之后，进行分割。\n",
    "维度变化：  \n",
    "$X:(B, T, C)$  \n",
    "$Q, K, V:(B, T, H)$  \n",
    "分割后：$Q^i, K^i, V^i:(B, n, T, s), \\ \\  H=n×s$  \n",
    "点击+缩放：$(B, n, T, T)$  \n",
    "softmax：$(B, n, T, T)$  \n",
    "与$V^i$相乘：$(B, n, T, s)$  \n",
    "拼接输出：$(B, T, H)$，与输入维度一致  \n",
    "后续无变化。\n",
    "\n",
    "多头注意力，相比单头注意力，通过多个不同的子空间用于关于不同结构上的特征。\n",
    "\n",
    "参数和单头注意力一样多，但计算上可以并行，提高计算效率。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6048b1cb-c1ec-46c0-8743-bb75f059ce49",
   "metadata": {},
   "source": [
    "**掩码自注意力**的另一个名称是因果自注意力。\n",
    "\n",
    "掩码多头注意力，维度变化与多头注意力是一样的。\n",
    "\n",
    "两者的主要区别是在softmax这个步骤上。掩码多头注意力会在这个分数矩阵上加上一个掩码矩阵，通常是下三角矩阵，将未来位置的得分设置为-inf，使得softmax后这些位置的权重接近0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a643faa-5509-4926-83c5-c97d065812c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0182,  1.1535, -1.7100, -0.2435,  1.1991],\n",
      "        [-1.1976,  0.1862,  0.9975, -0.6647,  0.8301],\n",
      "        [ 1.0701,  1.3209, -0.5289,  0.0137, -0.2921],\n",
      "        [ 0.9137,  0.3797, -0.1829, -2.7691,  0.4461],\n",
      "        [ 2.1975,  0.3053, -0.7171, -1.1248,  0.7243]])\n",
      "tensor([[ 1.0182e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "        [-1.1976e+00,  1.8616e-01, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "        [ 1.0701e+00,  1.3209e+00, -5.2889e-01, -1.0000e+09, -1.0000e+09],\n",
      "        [ 9.1374e-01,  3.7970e-01, -1.8290e-01, -2.7691e+00, -1.0000e+09],\n",
      "        [ 2.1975e+00,  3.0532e-01, -7.1708e-01, -1.1248e+00,  7.2425e-01]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2004, 0.7996, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4021, 0.5167, 0.0813, 0.0000, 0.0000],\n",
       "        [0.5140, 0.3013, 0.1717, 0.0129, 0.0000],\n",
       "        [0.6802, 0.1025, 0.0369, 0.0245, 0.1559]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "mask = torch.triu(torch.ones(5, 5), diagonal=1).bool()\n",
    "scores = torch.randn(5, 5)\n",
    "print(scores)\n",
    "scores = scores.masked_fill(mask, -1e9)\n",
    "print(scores)\n",
    "F.softmax(scores, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fd7d56-1018-4541-8533-13a85fb4f9d1",
   "metadata": {},
   "source": [
    "**交叉多头注意力**\n",
    "\n",
    "一般不需要掩码\n",
    "\n",
    "维度变化和多头注意力一样，只不过K,V用的是编码器输出，Q是解码输入。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958b5565-4835-4f39-8ddc-2aea94965846",
   "metadata": {},
   "source": [
    "**KV Cache**: 增量计算。这得益于矩阵乘法分片裁切的效果。  \n",
    "**多查询注意力（Multi-Query Attention, MQA）**：让所有头共享K，V值，只切割Q。具体做法是，在$K=XW_K$这步计算时，直接将K降到(B, C, s)大小，在点积缩放时进行广播。  \n",
    "**分组查询注意力 (Grouped Query Attention, GQA)**：引入超参数组数，不要所有头都一样了，而是在头里进行分组，组内用一样的K,V  \n",
    "**MLA（Multi-Head Local Attention, MLA）**: DeepSeek模型中使用，目的是为了减少内存的占用，有点像奇异值分解。 **待研究** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d05bf8-e8be-4baf-8fac-1131d6985e2e",
   "metadata": {},
   "source": [
    "### 2.3 前馈神经网络(FeedforwardNeural Network，FFN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f53a2b-de9f-49f7-b7dd-5bb2929cf8ca",
   "metadata": {},
   "source": [
    "前馈神经网络，又称为全连接层（Fully Connected Layer）或密集层（Dense Layer）。\n",
    "这里讲的很好：[FFN](https://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&mid=2247503288&idx=1&sn=ee4b2bc1b396a1e82725998911ded45d&chksm=fac05a64cdb7d372181dd1017b99a13d444bfc0c257002f8018560af83fde1bbf69f182c5f37&scene=178&cur_album_id=3876802058308993025#rd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5835c56-d6f7-46e4-9c8a-8bd54c45ac4f",
   "metadata": {},
   "source": [
    "数学表达上是简单的：  \n",
    "\n",
    "（1）升维：$X^{B\\times T\\times 4C} = X^{B\\times T\\times C}W_1^{B\\times C\\times 4C} + b_1^{B\\times T\\times 4C}$  \n",
    "（2）激活：$X^{B\\times T\\times 4C} = \\phi(X^{B\\times T\\times 4C})$  \n",
    "（3）降维：$X^{B\\times T\\times C} = X^{B\\times T\\times 4C}W_2^{B\\times 4C\\times C} + b_2^{B\\times T\\times C}$\n",
    "\n",
    "输出和输入维度一样。激活层必不可少。因为attention模块最后的结果是V的线性组合。并没有引入非线性。\n",
    "\n",
    "4C的原因是信息丢失补偿。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b76a913-3893-4d69-8169-8efa83a4d82e",
   "metadata": {},
   "source": [
    "### 2.4 混合专家模型 (Mixed Expert Models，MoEs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e51be36-d6ce-489a-907d-147dd985e2e6",
   "metadata": {},
   "source": [
    "核心构件包括两部分：专家网络，如FNN；门控网络  \n",
    "输出是TopK个专家的加权，一般K取很小的值，如1或2。 $output = \\sum_{i=1}^N G(x)_i\\times E_i(x)$   \n",
    "门控网络，$G(x)=softmax(TopK(W_gx+b_g, k))$  \n",
    "专家网络，$FFN(x)$    \n",
    "负载均衡约束：$L_{balance} = \\lambda\\cdot\\sum_{i=1}^Nf_i\\cdot P_i$\n",
    "总损失：$L_{total} = L_{task} + L_{balance} $    \n",
    "\n",
    "优点：在远低于稠密模型的计算成本下进行高效预训练。\n",
    "\n",
    "缺点：微调阶段容易泛化能力不足，导致过拟合；虽然 MoE 只激活部分参数进行推理，速度快于同等规模的稠密模型，但所有参数仍需加载到内存，导致较高的 VRAM 需求\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f915515-5850-43ec-89c0-883783b6d13c",
   "metadata": {},
   "source": [
    "## 3. 文本生成\n",
    "\n",
    "模拟训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f26e761-0439-4ca4-952d-b9849b9a506e",
   "metadata": {},
   "source": [
    "### 3.1 导入必要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d00a50f-aa0c-4fed-94a1-ce80233ca50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.amp import autocast, GradScaler\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe6ebfd-b208-4735-ac06-f816ad2d2587",
   "metadata": {},
   "source": [
    "### 3.2 设定超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3931aab-7ab2-425e-8f37-9578c9889b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 64\n",
    "seq_len = 128\n",
    "embed_dim = 64\n",
    "num_heads = 4\n",
    "num_encoder_layers = 2\n",
    "dropout= 0.2\n",
    "lr= 1e-3\n",
    "epochs= 20\n",
    "device= 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feb6d51-8eb3-4551-b823-088828a5e05c",
   "metadata": {},
   "source": [
    "### 3.3 处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0c3cabf-5093-42e1-b081-b806edcaf009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", cache_dir='./cache')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\", cache_dir=\"./cache\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "vocab_size = len(tokenizer)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "662d54a6-68d3-4c49-9074-da554355fe92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 4358\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 36718\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 3760\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc80c099-95de-4295-b841-1f6f7ccaa89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.model_max_length = seq_len\n",
    "tokenizer.model_input_names = [\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72d35f25-1ac2-43d7-b45b-e025e6bd53f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: 78 ['The', 'ĠHub', 'Ġhas', 'Ġsupport', 'Ġfor', 'Ġdozens', 'Ġof', 'Ġlibraries', 'Ġin', 'Ġthe', 'ĠOpen', 'ĠSource', 'Ġecosystem', '.', 'ĠThanks', 'Ġto', 'Ġthe', 'Ġhugging', 'face', '_', 'hub', 'ĠPython', 'Ġlibrary', ',', 'Ġit', 'âĢ', 'Ļ', 's', 'Ġeasy', 'Ġto', 'Ġenable', 'Ġsharing', 'Ġyour', 'Ġmodels', 'Ġon', 'Ġthe', 'ĠHub', '.', 'ĠThe', 'ĠHub', 'Ġsupports', 'Ġmany', 'Ġlibraries', ',', 'Ġand', 'Ġwe', 'âĢ', 'Ļ', 're', 'Ġworking', 'Ġon', 'Ġexpanding', 'Ġthis', 'Ġsupport', '.', 'ĠWe', 'âĢ', 'Ļ', 're', 'Ġhappy', 'Ġto', 'Ġwelcome', 'Ġto', 'Ġthe', 'ĠHub', 'Ġa', 'Ġset', 'Ġof', 'ĠOpen', 'ĠSource', 'Ġlibraries', 'Ġthat', 'Ġare', 'Ġpushing', 'ĠMachine', 'ĠLearning', 'Ġforward', '.']\n"
     ]
    }
   ],
   "source": [
    "# 示例\n",
    "text = \"The Hub has support for dozens of libraries in the Open Source ecosystem. \\\n",
    "Thanks to the huggingface_hub Python library, it’s easy to enable sharing your models on the Hub. \\\n",
    "The Hub supports many libraries, and we’re working on expanding this support. \\\n",
    "We’re happy to welcome to the Hub a set of Open Source libraries that are pushing Machine Learning forward.\"\n",
    "\n",
    "# 分词\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(\"Tokens:\", len(tokens), tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3b5bfb2-03d2-4288-a40e-16bc5ce94b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, max_length=seq_len, padding=\"max_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ba79cf0-d2b0-4743-bb36-50ca376f9892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  464, 14699,   468,  1104,   329,  9264,   286, 12782,   287,   262,\n",
      "          4946,  8090, 13187,    13,  6930,   284,   262, 46292,  2550,    62]])}\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer(text, padding=True, truncation=True, max_length=20, return_tensors=\"pt\")\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b1d45b8-f897-4498-9c2a-e3f082f2343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = dataset.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "tokenized.set_format(type='torch', columns=[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85fa6436-65b0-4c4a-ba81-29141b84d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(tokenized[\"train\"], batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(tokenized[\"validation\"], batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5225c4f7-599d-4def-b9a1-e16391f58f9d",
   "metadata": {},
   "source": [
    "### 3.4 定义网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "165f98d5-c32f-4858-92e2-702370a42a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 旋转位置编码，对每个二维子空间进行旋转\n",
    "def apply_rope(x):\n",
    "    B, T, H, D = x.shape #输入，batch_size, seq_len, num_heads, head_dim\n",
    "    assert D % 2 == 0\n",
    "    half = D // 2\n",
    "    freqs = 1.0 / (10000 ** (torch.arange(0, half, device=x.device).float() / half)) # embed_dim/2 数组\n",
    "    pos = torch.arange(0, T, device=x.device).float()\n",
    "    angles = torch.einsum(\"i,j->ij\", pos, freqs) # 外积，T, half，爱因斯坦求和约定\n",
    "    sin, cos = angles.sin(), angles.cos()\n",
    "    sin = sin.unsqueeze(0).unsqueeze(2) # 添加维度占位\n",
    "    cos = cos.unsqueeze(0).unsqueeze(2)\n",
    "    x1, x2 = x[..., :half], x[..., half:] # 按最后一个维度切片\n",
    "    return torch.cat([x1 * cos - x2 * sin, x1 * sin + x2 * cos], dim=-1) # 利用广播机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1ca3fb0-fbd9-4580-9ce7-75af7270e638",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        assert embed_dim % num_heads == 0\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.wq = nn.Linear(embed_dim, embed_dim)\n",
    "        self.wk = nn.Linear(embed_dim, embed_dim)\n",
    "        self.wv = nn.Linear(embed_dim, embed_dim)\n",
    "        self.fc = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x, attention_mask=None):\n",
    "        B, T, D = x.shape # D: embed_dim\n",
    "        q = self.wq(x).view(B, T, self.num_heads, self.head_dim).transpose(1, 2) # B, num_heads, T, head_dim\n",
    "        k = self.wk(x).view(B, T, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        v = self.wv(x).view(B, T, self.num_heads, self.head_dim).transpose(1, 2)        \n",
    "\n",
    "        q = apply_rope(q.transpose(1, 2)).transpose(1, 2) # 先和apply_rope对齐，B, T, num_heads, head_dim ---> B, num_heads, T, head_dim\n",
    "        k = apply_rope(k.transpose(1, 2)).transpose(1, 2)\n",
    "        attention_scores = (q @ k.transpose(-2, -1)) / math.sqrt(self.head_dim) # B, num_heads, T, T\n",
    "        if attention_mask is not None: # attention mask的形状 T, T 会被广播到 B, num_heads, T, T\n",
    "            attention_scores = attention_scores.masked_fill(attention_mask, float('-inf'))\n",
    "        attention_weights  = torch.softmax(attention_scores, dim=-1) # B, num_heads, T, T\n",
    "\n",
    "        attention_output = attention_weights @ v  #  B, num_heads, T, head_dim\n",
    "        attention_output = attention_output.transpose(1, 2).contiguous().view(B, T, D)\n",
    "        return self.fc(attention_output) # B, T, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fd124fa-7352-4ab4-8386-e47a8544ebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, dropout):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttention(embed_dim, num_heads)\n",
    "        self.ln1 = nn.LayerNorm(embed_dim)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim*4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(embed_dim*4, embed_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.ln2 = nn.LayerNorm(embed_dim)\n",
    "    \n",
    "    def forward(self, x, attention_mask=None):\n",
    "        attention_out = self.attention(x, attention_mask=attention_mask) # 多头自注意力输出\n",
    "        x = self.ln1(x+attention_out) # 残差连接\n",
    "        ff_out = self.ff(x) # feedforward 输出\n",
    "        return self.ln2(x + ff_out) # 归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a53a57ff-939d-49ac-be8b-5ab55a55a97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerLM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.blocks = nn.ModuleList([TransformerBlock(embed_dim, num_heads, dropout) for _ in range(num_layers)]) # 列表推导式，堆叠Transformer块\n",
    "        self.ln = nn.LayerNorm(embed_dim)\n",
    "        self.head = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x): # 输入X  batch_size, seq_len\n",
    "        B, T = x.shape\n",
    "        tok = self.token_emb(x) # 词嵌入 batch_size, seq_len, embed_dim : B, T, embed_dim(C/D)\n",
    "        mask = torch.triu(torch.ones(T, T, device=x.device), diagonal=1).bool()\n",
    "        for block in self.blocks:\n",
    "            tok = block(tok, attention_mask=mask)\n",
    "        tok = self.ln(tok)\n",
    "        \n",
    "        return self.head(tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b942d1b4-c4f7-4916-a6b9-601d47d067ba",
   "metadata": {},
   "source": [
    "### 3.5 实例化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa68050b-9b9f-4cf4-9d50-4e17c1c7e308",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerLM(vocab_size, embed_dim, num_heads, num_encoder_layers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e265479-9da2-4670-9e5f-59935ef2d476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "TransformerLM                            --\n",
       "├─Embedding: 1-1                         3,216,448\n",
       "├─ModuleList: 1-2                        --\n",
       "│    └─TransformerBlock: 2-1             --\n",
       "│    │    └─MultiHeadAttention: 3-1      16,640\n",
       "│    │    └─LayerNorm: 3-2               128\n",
       "│    │    └─Sequential: 3-3              33,088\n",
       "│    │    └─LayerNorm: 3-4               128\n",
       "│    └─TransformerBlock: 2-2             --\n",
       "│    │    └─MultiHeadAttention: 3-5      16,640\n",
       "│    │    └─LayerNorm: 3-6               128\n",
       "│    │    └─Sequential: 3-7              33,088\n",
       "│    │    └─LayerNorm: 3-8               128\n",
       "├─LayerNorm: 1-3                         128\n",
       "├─Linear: 1-4                            3,266,705\n",
       "=================================================================\n",
       "Total params: 6,583,249\n",
       "Trainable params: 6,583,249\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e19683-26fc-4d4d-82b9-acef116dddbd",
   "metadata": {},
   "source": [
    "### 3.6 选择损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b657f6a2-536c-4bc6-87e4-5caee0389757",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "scaler = GradScaler()\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e829393b-8a5b-428e-8cfe-d30fccc02129",
   "metadata": {},
   "source": [
    "### 3.7 验证函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "842d666e-ae78-4496-bcf7-38a46e4cb7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            x = batch[\"input_ids\"][:, :-1].to(device)\n",
    "            y = batch[\"input_ids\"][:, 1:].to(device)\n",
    "            with autocast(device_type=device):\n",
    "                logits = model(x)\n",
    "                loss = loss_fn(logits.view(-1, vocab_size), y.view(-1))\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd5d05a-e16f-4192-842d-301de90cf93d",
   "metadata": {},
   "source": [
    "### 3.8 文本生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45c71f5e-393c-4d70-95f9-31f3c82d3ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_p_sampling(logits, temperature=1.0, top_p=0.9, repetition_penalty=1.1, past_tokens=None):\n",
    "    logits = logits / temperature\n",
    "    if past_tokens is not None:\n",
    "        logits[past_tokens] /= repetition_penalty\n",
    "    sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "    cumulative_probs = torch.cumsum(torch.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "    sorted_indices_to_keep = cumulative_probs <= top_p\n",
    "    sorted_indices_to_keep[..., 1:] = sorted_indices_to_keep[..., :-1].clone()\n",
    "    sorted_indices_to_keep[..., 0] = 1\n",
    "    indices_to_keep = sorted_indices[sorted_indices_to_keep]\n",
    "    filtered_logits = logits[indices_to_keep]\n",
    "    probs = torch.softmax(filtered_logits, dim=-1)\n",
    "    sampled_idx = torch.multinomial(probs, num_samples=1)\n",
    "    return indices_to_keep[sampled_idx]\n",
    "\n",
    "def generate_text(model, tokenizer, prompt, max_new_tokens=50, temperature=1.0, top_p=0.9, repetition_penalty=1.1):\n",
    "    model.eval()\n",
    "    tokens = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "    tokens = tokens[:, :seq_len]\n",
    "    for _ in range(max_new_tokens):\n",
    "        input_ids = tokens[:, -seq_len:]\n",
    "        with torch.no_grad(), autocast(device_type=device):\n",
    "            logits = model(input_ids)\n",
    "        next_token_logits = logits[:, -1, :].squeeze()\n",
    "        next_token = top_p_sampling(next_token_logits, temperature=temperature, \n",
    "                                    top_p=top_p, repetition_penalty=repetition_penalty, past_tokens=tokens[0])\n",
    "        tokens = torch.cat([tokens, next_token.unsqueeze(0)], dim=1)\n",
    "    return tokenizer.decode(tokens[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052654fc-4093-4649-8307-04f7ddb272c7",
   "metadata": {},
   "source": [
    "### 3.9 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3806c19b-22b3-4392-bdab-912eb64bf9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_clip = 1.0  # 梯度裁剪阈值\n",
    "save_path = \"model_checkpoint.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdab1ff5-1867-4aa9-9d45-277d4344f0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Max GPU memory: 4865.39 MB\n",
      "Epoch 1: train loss = 7.0442, val loss = 6.4890, time = 39.90s\n",
      "\n",
      "Sample generated text:\n",
      "The meaning of life is hired on the Ve of successfully . The Packmar pra ch point performed received revolutionaries in 16 11 Bus could Miracle contains radiationhensA designer , Xonsense or once 13res November more retaining conviction , Monk Brothers syrup . Chel stressed appraisal works honorary and wording\n",
      "\n",
      "[Epoch 2] Max GPU memory: 4864.96 MB\n",
      "Epoch 2: train loss = 6.1204, val loss = 6.1776, time = 39.75s\n",
      "\n",
      "Sample generated text:\n",
      "The meaning of life is one M.J freewayaicological where the foundation flank Union invre and Mendraendicvening Priates . H mad staple Form became spawn East tour would monitored on March Auburn of sub ?ki filming over 26ised when 185egress ,\n",
      "\n",
      "[Epoch 3] Max GPU memory: 4864.96 MB\n",
      "Epoch 3: train loss = 5.7270, val loss = 6.0318, time = 40.09s\n",
      "\n",
      "Sample generated text:\n",
      "The meaning of life is supposed ridge runs video on winterbs for the formula they finally in society warning . Peck and announce blocks quantitiesan thening religious partners meetings fix their wrinkuri Villa should projects in until 1890 , probably enable the night significant kins Conf el storytelling feeds after regional\n",
      "\n",
      "[Epoch 4] Max GPU memory: 4864.96 MB\n",
      "Epoch 4: train loss = 5.4615, val loss = 5.9438, time = 40.68s\n",
      "\n",
      "Sample generated text:\n",
      "The meaning of life is often associated with it , appointed grow . Potter occurs and Fischer for him basically pursuit of clinical Haitationsler earlier of closures reassith Seaross andorses downt deg under L & Iskkin design , Algeriaiewiczzy and extreme faiths rootosis resemble\n",
      "\n",
      "[Epoch 5] Max GPU memory: 4864.96 MB\n",
      "Epoch 5: train loss = 5.2660, val loss = 5.9036, time = 41.13s\n",
      "\n",
      "Sample generated text:\n",
      "The meaning of life is for the character . \n",
      " Aquaun Baja works while the instance in view had done a Eston work to whom processing allators — Manbottom monate aircraft population . The Church developed vocals of the main bias were disrupt rickle — such as writer\n",
      "\n",
      "[Epoch 6] Max GPU memory: 4864.96 MB\n",
      "Epoch 6: train loss = 5.1188, val loss = 5.8761, time = 41.52s\n",
      "\n",
      "Sample generated text:\n",
      "The meaning of life is preserves inside , from photos : And Imam varieties may have inundung musical genres is already sure for his chest , a bone est anthology met in large number of skill on 54 November 1918 to Sheffield battlefield dogs \" East matter avoidance with the technological existence , and\n",
      "\n",
      "[Epoch 7] Max GPU memory: 4864.96 MB\n",
      "Epoch 7: train loss = 4.9996, val loss = 5.8711, time = 41.87s\n",
      "\n",
      "Sample generated text:\n",
      "The meaning of life is read noted sperm , it sat all sources environment are resulted ; larger severe predators programmes comes in almost frantic schemes for smooth habitat ( interacting north ) north was used up into a per game . Time paragraphs also excel lead to an strongest version to their in by\n",
      "\n",
      "[Epoch 8] Max GPU memory: 4864.96 MB\n",
      "Epoch 8: train loss = 4.9066, val loss = 5.8627, time = 42.13s\n",
      "\n",
      "Sample generated text:\n",
      "The meaning of life is done by filming and delivery throughholes of noncommpe District teams , except published its present sites . \n",
      " , about one based on the musical chances of world policy often efficiently Lele and socks Australia Baghdvait technique through prosperity of William Munquez\n",
      "\n",
      "[Epoch 9] Max GPU memory: 4864.96 MB\n",
      "Epoch 9: train loss = 4.8245, val loss = 5.8668, time = 42.14s\n",
      "\n",
      "Sample generated text:\n",
      "The meaning of life is not a uncontrolled classic page [ s ] same . \n",
      " , under Doce Legion assembly praised Petad Juáre claiming for 27 April that Ke adults were captured by Yrence A Claytonies to World Jean Loose , an \" kingis Lemon\n",
      "\n",
      "[Epoch 10] Max GPU memory: 4864.96 MB\n",
      "Epoch 10: train loss = 4.7553, val loss = 5.8830, time = 42.03s\n",
      "\n",
      "Sample generated text:\n",
      "The meaning of life is one on the main track , the species are recognized sex simultaneously and crystallair out to different items . Simon Property critics lasts abnormalities caused Minnesota Canterbury some \" compensate suggests that issues this time off of time such as citizens pathways soc concerning 266 @-@ heavy\n",
      "\n",
      "[Epoch 11] Max GPU memory: 4864.96 MB\n",
      "Epoch 11: train loss = 4.6925, val loss = 5.8877, time = 42.01s\n",
      "\n",
      "Sample generated text:\n",
      "The meaning of life is held for peace assassin accused European centers , thinking Bringing T Jacksonville Crusher and such as Nijo local rulers ; for example . In response to MaeangAL ( teacher ) , using green techniques are nonaves on the masiter behaviour of a variety .\n",
      "\n",
      "[Epoch 12] Max GPU memory: 4864.96 MB\n",
      "Epoch 12: train loss = 4.6406, val loss = 5.8939, time = 42.04s\n",
      "\n",
      "Sample generated text:\n",
      "The meaning of life is being an poor oaks – Howell ( courtesy Strait @-@ , John Lefong ) is too named Oah because Cloftron , 'Malley is leading off breathe 129 . A burn analysis a rabbi species that references to mislead bird rifle\n",
      "\n",
      "[Epoch 13] Max GPU memory: 4864.96 MB\n",
      "Epoch 13: train loss = 4.5895, val loss = 5.9076, time = 42.12s\n",
      "\n",
      "Sample generated text:\n",
      "The meaning of life is a autographed song as Noundov : Case all and parodied experience after characters in gender , pointing alike said , India travel due to live action from the 2001 World Cup . Following Carroll Ickantitt asked Cart Times in early 1990 as a\n",
      "\n",
      "[Epoch 14] Max GPU memory: 4864.96 MB\n",
      "Epoch 14: train loss = 4.5439, val loss = 5.9154, time = 42.10s\n",
      "\n",
      "Sample generated text:\n",
      "The meaning of life is found on each other type . Unbek photons called Ched LLC , Half cell with Fully acts . High was the paranormal based in 1870 ' national bias as a Roman Catholicwile Family ' Sun Carantaur uses an American sitcom skateorah , commuting\n",
      "\n",
      "[Epoch 15] Max GPU memory: 4864.96 MB\n",
      "Epoch 15: train loss = 4.5014, val loss = 5.9311, time = 42.09s\n",
      "\n",
      "Sample generated text:\n",
      "The meaning of life is a spin considerably being related to do Stvl . Together are included the fox , praising unions their elements in raising . After gas technology in other incremental condensation and sacrifice considers lives Margon metaphors for the law lasting . Track attendance based with woodided rains\n",
      "\n",
      "[Epoch 16] Max GPU memory: 4864.96 MB\n",
      "Epoch 16: train loss = 4.4630, val loss = 5.9368, time = 42.13s\n",
      "\n",
      "Sample generated text:\n",
      "The meaning of life is similar to pygino to A Villro has a moving rule . Physost implications are astonished attention between 3D , Sioux from Kwa and Waynegelsen Centre erected as Cheipsangfordu Roadown Link by Lois of Celiawena\n",
      "\n",
      "[Epoch 17] Max GPU memory: 4864.96 MB\n",
      "Epoch 17: train loss = 4.4269, val loss = 5.9501, time = 42.18s\n",
      "\n",
      "Sample generated text:\n",
      "The meaning of life is done . \" flo viewers reverberatory I believe that know the II edit for Ulysses , had no longer have been largely other abilities 's rigging and reject them only they feel bright due to staff dogs and anxiety she permeel ( I Ghochemical\n",
      "\n",
      "[Epoch 18] Max GPU memory: 4864.96 MB\n",
      "Epoch 18: train loss = 4.3923, val loss = 5.9611, time = 42.27s\n",
      "\n",
      "Sample generated text:\n",
      "The meaning of life is a writing book film \" poet how Vanomt live on industryarian to the 5th Century slala s . The divin was Project Nicole managed to have attracted by the older ( Kenneth they 'ire inherent persecution as easyended within reviews when she\n",
      "\n",
      "[Epoch 19] Max GPU memory: 4864.96 MB\n",
      "Epoch 19: train loss = 4.3611, val loss = 5.9764, time = 42.24s\n",
      "\n",
      "Sample generated text:\n",
      "The meaning of life is percussion for balls under the attention basicym Quickens or slow bounds ! Ōzus ; it contains consistent gameplay as two wedding in vi even after the next relevance before Joyry . Innis switches place in Kirsch 's plan convinced hardcore ,\n",
      "\n",
      "[Epoch 20] Max GPU memory: 4864.96 MB\n",
      "Epoch 20: train loss = 4.3295, val loss = 5.9926, time = 42.21s\n",
      "\n",
      "Sample generated text:\n",
      "The meaning of life is alluded to age 1 and similar times lines . The two are rows from ha Kumpuosity prior : the site was an inevitable , Ram Luh bristam K @-@ Priest 's Museum of Christian and when stained availability of accomplished money past\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    start_time = time.time() # 开始时间\n",
    "    for batch in train_loader:\n",
    "        x = batch[\"input_ids\"][:, :-1].to(device)\n",
    "        y = batch[\"input_ids\"][:, 1:].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with autocast(device_type=device):\n",
    "            logits = model(x)\n",
    "            loss = loss_fn(logits.view(-1, vocab_size), y.view(-1))\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 梯度剪裁\n",
    "        scaler.unscale_(optimizer)\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        \n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    val_loss = evaluate(model, val_loader)\n",
    "    end_time = time.time() # 结束时间\n",
    "\n",
    "    # 保存模型\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "\n",
    "    # 显示内存和时间\n",
    "    if torch.cuda.is_available():\n",
    "        mem_allocated = torch.cuda.max_memory_allocated() / 1024**2\n",
    "        print(f\"[Epoch {epoch+1}] Max GPU memory: {mem_allocated:.2f} MB\")\n",
    "    print(f\"Epoch {epoch+1}: train loss = {avg_loss:.4f}, val loss = {val_loss:.4f}, time = {end_time - start_time:.2f}s\")\n",
    "\n",
    "    sample = generate_text(model, tokenizer, prompt=\"The meaning of life is\", temperature=1.2, top_p=20)\n",
    "    print(f\"\\nSample generated text:\\n{sample}\\n\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
